{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Know what interests famous people have by reading their quotes\n",
    "\n",
    "![](https://i.imgur.com/Zemp7ZZ.png)\n",
    "\n",
    "Sometimes we all need a little inspiration or advice on how to react to given\n",
    "life situations, whether on how to be a valuable person, a better friend, or\n",
    "how to react to something adverse. Various famous and successful people have\n",
    "said things that we all can find helpful. There is a website, \"Quotes to scrape\",\n",
    "that offers dozens, if not hundreds, of such quotes.\n",
    "\n",
    "Web-scraping is a gathering of useful information from a website of interest and\n",
    "presenting it in a meaningful way.\n",
    "\n",
    "In this project read in a list of quotes from famous people using the\n",
    "\"quotes to scrape\" website, based on the default top quotes, or quotes filtered\n",
    "based on various subjects:\n",
    " - love\n",
    " - inspirational\n",
    " - life\n",
    " - humor\n",
    " - books\n",
    " - reading\n",
    " - friendship\n",
    " - friends\n",
    " - truth\n",
    " - similes.\n",
    "\n",
    "Once you pick a subject of interest a request will be made over the web and\n",
    "an http response document will be returned by the website from where the request\n",
    "was submitted.\n",
    "\n",
    "Information will be extracted from the document using the Python library,\n",
    "BeautifulSoup. Here is some general information from their documentation:\n",
    "\n",
    "\"Beautiful Soup is a Python library for pulling data out of HTML and XML files.\n",
    "It works with your favorite parser to provide idiomatic ways of navigating, \n",
    "searching, and modifying the parse tree. It commonly saves programmers hours \n",
    "or days of work.\"\n",
    "\n",
    "We will analyze the data and report\n",
    " - author's name (the person being quoted)\n",
    " - an 'about' link, giving information about the author\n",
    " - the text of the quote\n",
    "\n",
    "## We will then create a dataset, storing the gathered information\n",
    "\n",
    "Using the authors and corresponding quotes listed, create a list of dictionaries,\n",
    "each one with an entry containing the author's name, a link to his/her about info,\n",
    "and the quote itself. This dataset will be stored as a tabular database, in CSV\n",
    "format and can be downloaded for subsequent data analysis and machine learning\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Jovian platform is where this notebook was developed\n",
    "# and copies of it are maintained \n",
    "#\n",
    "# since this notebook's initial development is complete, we \n",
    "# will not use these cells but keep them here for reference\n",
    "#!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "#jovian.commit(project=\"dataanalyst-bootcamp-project1-web-scraping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the libraries\n",
    " - requests allows this notebook to interact with websites\n",
    " - bs4, or Beautiful Soup allows us to parse information from HTML documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install install requests --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet # note we're using BeautifulSoup V4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a web page from the site containing famous quotes (see https://quotes.toscrape.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/tKxKtG7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function read_page_from_quotes_toscrape\n",
    "function to get author/quote data from the website\n",
    "return the response\n",
    "params:\n",
    "    url = base url for website we're scraping\n",
    "    page = page number if we're paginating \n",
    "        NOTE: even if we're not paginating we need to supply a page number to get \n",
    "        a full amount of quotes in the text, for the first page, if any are in the\n",
    "        given tag, selected or default (see below)\n",
    "    (optional) tag = filter for quotes we're requesting\n",
    "'''\n",
    "def read_page_from_quotes_toscrape(url, page, tag):\n",
    "    response = ''\n",
    "    quotes_url = url\n",
    "    if tag != '':\n",
    "        quotes_url += '/tag/' + tag\n",
    "    if page != '':\n",
    "        quotes_url += '/page/' + str(page)\n",
    "    else:\n",
    "        raise Exception('enter a valid page number or tag to filter')\n",
    "    quotes_url += '/'\n",
    "    # for debugging: print(quotes_url)\n",
    "    response = requests.get(quotes_url)\n",
    "\n",
    "    # Check for success in reading the page\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load {}'.format(url))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the returned web page we into a Beautiful Soup Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "convert the web page to a BeautifulSoup object\n",
    "'''\n",
    "def parse_page_with_bs4(page):\n",
    "    html_source = BeautifulSoup(page, 'html.parser')\n",
    "    return html_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the list of quotes and their authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " function get_quotes_and_authors \n",
    " function to scrape the data\n",
    " params:\n",
    "  - bs4 document\n",
    "  - base url for building author links\n",
    " returns:\n",
    "  - tuple of quotes list and corresponding authors list\n",
    "'''\n",
    "def get_quotes_and_authors(document, base_url):\n",
    "    quote_list_from_pages = []\n",
    "    authors_list_from_pages = []\n",
    "    # get all authors and their quotes in a list of tags\n",
    "    tags = document.find_all('div', class_='quote')\n",
    "\n",
    "    # append the quotes and author links\n",
    "    for i in tags:\n",
    "        # quotes\n",
    "        quote = i.find('span').text\n",
    "        quote_list_from_pages.append(quote)\n",
    "        # authors\n",
    "        author_link = i.find('a')['href']\n",
    "        authors_list_from_pages.append(base_url+author_link)\n",
    "        \n",
    "    return (quote_list_from_pages,authors_list_from_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get quote category from the user, request the document from the website, and create Python dictionary structures for subsequent storage into the dataset.\n",
    "\n",
    "You will be prompted for a quote category out of the categories listed.\n",
    "Once you type it in, we will\n",
    " - get the data from the website\n",
    " - create a Beautiful Soup object containing the data\n",
    " - build Python dictionaries of the authors and their quotes\n",
    "\n",
    "This data will be ready for subsequent processing into the desired .csv file, the dataset that is output by this web scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a category of quotes from the list below. For a random list of quotes, press <enter>:\n",
      "love \n",
      "\n",
      "inspirational \n",
      "\n",
      "life \n",
      "\n",
      "humor \n",
      "\n",
      "books \n",
      "\n",
      "reading \n",
      "\n",
      "friendship \n",
      "\n",
      "friends \n",
      "\n",
      "truth \n",
      "\n",
      "simile \n",
      "\n",
      "Tag: \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this is the main program. it will get the desired\n",
    "# subject from the user to get related quotes, request them\n",
    "# from the web site, and convert them into tabular data\n",
    "instructions = 'Choose a category of quotes from the list below. For a random list of quotes, press <enter>:'\n",
    "    \n",
    "all_tags = [\n",
    "'love',\n",
    "'inspirational',\n",
    "'life',\n",
    "'humor',\n",
    "'books',\n",
    "'reading',\n",
    "'friendship',\n",
    "'friends',\n",
    "'truth',\n",
    "'simile']\n",
    "\n",
    "print(instructions)\n",
    "for tag in all_tags:\n",
    "    print(tag,'\\n')\n",
    "    \n",
    "quote_subject = input(\"Tag: \")\n",
    "\n",
    "if quote_subject not in all_tags:\n",
    "    quote_subject = ''\n",
    "\n",
    "# reserve a place to save all quotes and authors retrieved\n",
    "quote_list = []\n",
    "author_list = []\n",
    "\n",
    "# page number for iterating through all the pages\n",
    "page_num = 1\n",
    "\n",
    "base_url = 'https://quotes.toscrape.com'\n",
    "topic_url = base_url + '/page/' + str(page_num)\n",
    "\n",
    "# get a web page from quotes.toscrape.com\n",
    "page = read_page_from_quotes_toscrape(base_url, page_num, quote_subject)\n",
    "# convert the page into a BeautifulSoup object\n",
    "document = parse_page_with_bs4(page.text)\n",
    "\n",
    "# extract the first page's quotes and authors\n",
    "(quotes,authors) = get_quotes_and_authors(document, base_url)\n",
    "for quote in quotes:\n",
    "    quote_list.append(quote)\n",
    "for author in authors:\n",
    "    author_list.append(author)\n",
    "\n",
    "# see if there are more pages to scrape by checking the number of 'next' links\n",
    "pager = document.find_all('li', class_='next')\n",
    "\n",
    "while len(pager) == 1:\n",
    "    # for debugging only: print('entering while loop',pager)\n",
    "    page_num += 1\n",
    "    page = read_page_from_quotes_toscrape(base_url, page_num, quote_subject)\n",
    "    document = parse_page_with_bs4(page.text)\n",
    "    (quotes,authors) = get_quotes_and_authors(document, base_url)\n",
    "    for quote in quotes:\n",
    "        quote_list.append(quote)\n",
    "    for author in authors:\n",
    "        author_list.append(author)\n",
    "    pager = document.find_all('li', class_='next')\n",
    "    \n",
    "for i in range(len(author_list)):\n",
    "    author = author_list[i]\n",
    "    author = author[len(base_url) + len('/author/'):].strip()\n",
    "    author = author.replace('-',' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset from what was just read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function write_csv\n",
    "given a list of dictionaries, assuming the first item is a header,\n",
    "create a csv file for all items.\n",
    "\n",
    "items consist of:\n",
    " - list of authors\n",
    " - list of quotes, corresponding to each item in the list of authors\n",
    "\n",
    "output a .csv file at the given path\n",
    "'''\n",
    "def write_csv(items, path):\n",
    "    \"\"\"Write a list of dictionaries to a CSV file\"\"\"\n",
    "    with open(path, 'w') as f:\n",
    "        if len(items) == 0:\n",
    "            return\n",
    "        headers = list(items[0].keys())\n",
    "        #f.write(','.join(headers) + '\\n')\n",
    "        for item in items:\n",
    "            values = []\n",
    "            for header in headers:\n",
    "                values.append(str(item.get(header, \"\")))\n",
    "            f.write(','.join(values) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function build_dictionary\n",
    "given a header dictionary, list of all quoted authors,\n",
    "and their quotes, build a dictionary list consisting of\n",
    " - the headers\n",
    " - the entries (author, author's about link, quote)\n",
    "'''\n",
    "def build_dictionary_list(headers,authors,quotes):\n",
    "    \n",
    "    result = []\n",
    "    header_line = {\n",
    "        'key1' : headers[0],\n",
    "        'key2' : headers[1],\n",
    "        'key3' : headers[2]\n",
    "    }\n",
    "    result.append(header_line)\n",
    "\n",
    "    for i in range(len(author_list)):\n",
    "        author_about = author_list[i]\n",
    "        author = author_about[len(base_url) + len('/author/'):].strip()\n",
    "        author = author.replace('-',' ')\n",
    "        quote = quote_list[i]\n",
    "        quote = quote.replace(',',' ')\n",
    "        dict_entry = {\n",
    "            'key1' : author,\n",
    "            'key2' : author_about,\n",
    "            'key3' : quote #quote_list[i]\n",
    "        }\n",
    "        result.append(dict_entry)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Format the data for the .CSV file\n",
    "\n",
    "list out the headers in the top line, then pass in the authors and quotes\n",
    "we'll receive a list of dictionary entries that can be saved\n",
    "'''\n",
    "header = ['author', 'about', 'quote']\n",
    "csv_data = build_dictionary_list(header,author_list,quote_list)\n",
    "\n",
    "# use the requested subject in the file name\n",
    "if quote_subject == '':\n",
    "    quote_subject = 'general'\n",
    "    \n",
    "#print('the csv data:','\\n',csv_data)\n",
    "filename = 'quotes_'+quote_subject+'.csv'\n",
    "write_csv(csv_data,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>about</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J K Rowling</td>\n",
       "      <td>https://quotes.toscrape.com/author/J-K-Rowling</td>\n",
       "      <td>“It is our choices  Harry  that show what we t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>https://quotes.toscrape.com/author/Jane-Austen</td>\n",
       "      <td>“The person  be it gentleman or lady  who has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>https://quotes.toscrape.com/author/Marilyn-Monroe</td>\n",
       "      <td>“Imperfection is beauty  madness is genius and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>https://quotes.toscrape.com/author/Harper-Lee</td>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Madeleine LEngle</td>\n",
       "      <td>https://quotes.toscrape.com/author/Madeleine-L...</td>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>https://quotes.toscrape.com/author/Mark-Twain</td>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dr Seuss</td>\n",
       "      <td>https://quotes.toscrape.com/author/Dr-Seuss</td>\n",
       "      <td>“A person's a person  no matter how small.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>George R R Martin</td>\n",
       "      <td>https://quotes.toscrape.com/author/George-R-R-...</td>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                              about  \\\n",
       "0     Albert Einstein  https://quotes.toscrape.com/author/Albert-Eins...   \n",
       "1         J K Rowling     https://quotes.toscrape.com/author/J-K-Rowling   \n",
       "2     Albert Einstein  https://quotes.toscrape.com/author/Albert-Eins...   \n",
       "3         Jane Austen     https://quotes.toscrape.com/author/Jane-Austen   \n",
       "4      Marilyn Monroe  https://quotes.toscrape.com/author/Marilyn-Monroe   \n",
       "..                ...                                                ...   \n",
       "95         Harper Lee      https://quotes.toscrape.com/author/Harper-Lee   \n",
       "96   Madeleine LEngle  https://quotes.toscrape.com/author/Madeleine-L...   \n",
       "97         Mark Twain      https://quotes.toscrape.com/author/Mark-Twain   \n",
       "98           Dr Seuss        https://quotes.toscrape.com/author/Dr-Seuss   \n",
       "99  George R R Martin  https://quotes.toscrape.com/author/George-R-R-...   \n",
       "\n",
       "                                                quote  \n",
       "0   “The world as we have created it is a process ...  \n",
       "1   “It is our choices  Harry  that show what we t...  \n",
       "2   “There are only two ways to live your life. On...  \n",
       "3   “The person  be it gentleman or lady  who has ...  \n",
       "4   “Imperfection is beauty  madness is genius and...  \n",
       "..                                                ...  \n",
       "95  “You never really understand a person until yo...  \n",
       "96  “You have to write the book that wants to be w...  \n",
       "97  “Never tell the truth to people who are not wo...  \n",
       "98        “A person's a person  no matter how small.”  \n",
       "99  “... a mind needs books as a sword needs a whe...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "view the data using Pandas\n",
    "'''\n",
    "import pandas as pd\n",
    "pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jovian.commit(project=\"dataanalyst-bootcamp-project1-web-scraping\", outputs=[filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this project we have gathered information about famous people from throughout history by scraping quotes from them from this https://quotes.toscrape.com\n",
    "\n",
    "The metadata gathered there shares some of the things they've said and offers links to each person being quoted for more general information about them.\n",
    "\n",
    "Using the python libraries requests, BeautifulSoup, and pandas the following steps are taken:\n",
    " - scraped the website, gathering names, quotes, and informational links\n",
    " - to do this we\n",
    "     - prompt the user to enter a quote category by selecting a tag name as given above\n",
    "     - use the requests library to scrape the website\n",
    "     - use the Beautiful Soup library to parse metadata from the web page returned (name, authors about-link, and quote)\n",
    " - create a dataset in the form of a .csv file given the tag name entered by the user.\n",
    " \n",
    "### Data scraped from the website is now available alongside this notebook's enclosing folder.\n",
    "\n",
    "If you are running this notebook on a Jupyter platform, refer to the menu at the top of the page, select\n",
    "'File | open'. A new tab will be opened in the browser. Locate and download 'quotes_<tag>.csv' If no tag was picked then the file will be named 'quotes_general.csv'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was useful while studying Pandas and its management of csv files\n",
    "#help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filename)\n",
    "#csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "    - scrape multiple websites for additional quotes/people and combine the metadata with what is here\n",
    "    - gather more in-depth information about each person being quoted by following the link provided in the metadata obtained from this scraping\n",
    "    - for other webscraping projects, use Selenium to scrape websites with dynamically changing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[jovian project](https://jovian.ai/learn/zero-to-data-analyst-bootcamp/lesson/web-scraping-and-rest-apis)\n",
    "\n",
    "[information about web scraping](https://en.wikipedia.org/wiki/Web_scraping)\n",
    "\n",
    "[Beautiful Soup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "[HTTP requests using Python](https://docs.python-requests.org/en/master/)\n",
    "\n",
    "[Pandas: (the tool used for csv file management in this project)](https://pandas.pydata.org/docs/pandas.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, the Jovian platform is where this project was developed\n",
    "# and submitted for evaluation. We don't do that here as this work\n",
    "# is here for demonstration only\n",
    "#jovian.submit(assignment=\"zerotoanalyst-project1\", outputs=filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
